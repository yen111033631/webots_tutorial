current machine: neaf2080
current path: /home/neaf2080/code/yen/webots_arm/integration/controllers/train_RL_env
current time: 2024-04-09 20:34:12
-----------------------------------
num_frames: 1500000
-----------------------------------
DQN hyperparameter
LR:				0.0002
TAU:			0.005
MAX_BUFF:		100000
EPS_DECAY:		500000
BATCH_SIZE:		128
LEARNING_START:	10000
-----------------------------------
env hyperparameter
reward_slope:			-10.0
big_negative_reward:	-500.0
-----------------------------------
i_frame:	100,	i_episode:	4,	mean reward:	-671.7,	is_saved_model:	True
i_frame:	200,	i_episode:	14,	mean reward:	-542.11,	is_saved_model:	True
i_frame:	300,	i_episode:	22,	mean reward:	-561.48,	is_saved_model:	False
i_frame:	400,	i_episode:	30,	mean reward:	-552.64,	is_saved_model:	False
i_frame:	500,	i_episode:	37,	mean reward:	-570.26,	is_saved_model:	False
i_frame:	600,	i_episode:	39,	mean reward:	-637.35,	is_saved_model:	False
i_frame:	700,	i_episode:	46,	mean reward:	-627.96,	is_saved_model:	False
i_frame:	800,	i_episode:	53,	mean reward:	-579.85,	is_saved_model:	False
i_frame:	900,	i_episode:	54,	mean reward:	-596.98,	is_saved_model:	False
i_frame:	1000,	i_episode:	61,	mean reward:	-585.02,	is_saved_model:	False
i_frame:	1100,	i_episode:	65,	mean reward:	-575.29,	is_saved_model:	False
i_frame:	1200,	i_episode:	73,	mean reward:	-594.55,	is_saved_model:	False
i_frame:	1300,	i_episode:	81,	mean reward:	-564.11,	is_saved_model:	False
i_frame:	1400,	i_episode:	84,	mean reward:	-541.69,	is_saved_model:	True
i_frame:	1500,	i_episode:	96,	mean reward:	-530.65,	is_saved_model:	True
i_frame:	1600,	i_episode:	107,	mean reward:	-537.92,	is_saved_model:	False
i_frame:	1700,	i_episode:	112,	mean reward:	-544.63,	is_saved_model:	False
i_frame:	1800,	i_episode:	118,	mean reward:	-561.38,	is_saved_model:	False
i_frame:	1900,	i_episode:	121,	mean reward:	-608.63,	is_saved_model:	False
i_frame:	2000,	i_episode:	130,	mean reward:	-544.44,	is_saved_model:	False
i_frame:	2100,	i_episode:	138,	mean reward:	-593.01,	is_saved_model:	False
i_frame:	2200,	i_episode:	142,	mean reward:	-557.11,	is_saved_model:	False
i_frame:	2300,	i_episode:	145,	mean reward:	-550.03,	is_saved_model:	False
i_frame:	2400,	i_episode:	149,	mean reward:	-545.28,	is_saved_model:	False
i_frame:	2500,	i_episode:	152,	mean reward:	-556.14,	is_saved_model:	False
i_frame:	2600,	i_episode:	156,	mean reward:	-595.67,	is_saved_model:	False
i_frame:	2700,	i_episode:	159,	mean reward:	-646.44,	is_saved_model:	False
i_frame:	2800,	i_episode:	163,	mean reward:	-634.44,	is_saved_model:	False
i_frame:	2900,	i_episode:	167,	mean reward:	-627.43,	is_saved_model:	False
i_frame:	3000,	i_episode:	174,	mean reward:	-593.92,	is_saved_model:	False
i_frame:	3100,	i_episode:	176,	mean reward:	-620.15,	is_saved_model:	False
i_frame:	3200,	i_episode:	185,	mean reward:	-566.15,	is_saved_model:	False
i_frame:	3300,	i_episode:	193,	mean reward:	-567.8,	is_saved_model:	False
i_frame:	3400,	i_episode:	194,	mean reward:	-583.48,	is_saved_model:	False
i_frame:	3500,	i_episode:	199,	mean reward:	-581.17,	is_saved_model:	False
i_frame:	3600,	i_episode:	205,	mean reward:	-609.91,	is_saved_model:	False
i_frame:	3700,	i_episode:	211,	mean reward:	-571.29,	is_saved_model:	False
i_frame:	3800,	i_episode:	220,	mean reward:	-575.53,	is_saved_model:	False
i_frame:	3900,	i_episode:	228,	mean reward:	-522.14,	is_saved_model:	True
i_frame:	4000,	i_episode:	233,	mean reward:	-520.91,	is_saved_model:	True
i_frame:	4100,	i_episode:	238,	mean reward:	-642.31,	is_saved_model:	False
i_frame:	4200,	i_episode:	248,	mean reward:	-548.26,	is_saved_model:	False
i_frame:	4300,	i_episode:	254,	mean reward:	-554.12,	is_saved_model:	False
i_frame:	4400,	i_episode:	255,	mean reward:	-560.8,	is_saved_model:	False
i_frame:	4500,	i_episode:	258,	mean reward:	-560.77,	is_saved_model:	False
i_frame:	4600,	i_episode:	268,	mean reward:	-536.71,	is_saved_model:	False
i_frame:	4700,	i_episode:	276,	mean reward:	-576.38,	is_saved_model:	False
i_frame:	4800,	i_episode:	284,	mean reward:	-571.4,	is_saved_model:	False
i_frame:	4900,	i_episode:	288,	mean reward:	-555.78,	is_saved_model:	False
i_frame:	5000,	i_episode:	296,	mean reward:	-552.57,	is_saved_model:	False
i_frame:	5100,	i_episode:	302,	mean reward:	-553.58,	is_saved_model:	False
i_frame:	5200,	i_episode:	307,	mean reward:	-591.18,	is_saved_model:	False
i_frame:	5300,	i_episode:	313,	mean reward:	-579.17,	is_saved_model:	False
i_frame:	5400,	i_episode:	318,	mean reward:	-563.78,	is_saved_model:	False
i_frame:	5500,	i_episode:	320,	mean reward:	-603.95,	is_saved_model:	False
i_frame:	5600,	i_episode:	327,	mean reward:	-622.96,	is_saved_model:	False
i_frame:	5700,	i_episode:	329,	mean reward:	-586.07,	is_saved_model:	False
i_frame:	5800,	i_episode:	333,	mean reward:	-553.9,	is_saved_model:	False
i_frame:	5900,	i_episode:	339,	mean reward:	-600.21,	is_saved_model:	False
i_frame:	6000,	i_episode:	341,	mean reward:	-640.66,	is_saved_model:	False
i_frame:	6100,	i_episode:	344,	mean reward:	-615.4,	is_saved_model:	False
i_frame:	6200,	i_episode:	356,	mean reward:	-524.02,	is_saved_model:	False
i_frame:	6300,	i_episode:	362,	mean reward:	-562.51,	is_saved_model:	False
i_frame:	6400,	i_episode:	368,	mean reward:	-571.81,	is_saved_model:	False
i_frame:	6500,	i_episode:	382,	mean reward:	-524.42,	is_saved_model:	False
i_frame:	6600,	i_episode:	383,	mean reward:	-554.73,	is_saved_model:	False
i_frame:	6700,	i_episode:	388,	mean reward:	-615.82,	is_saved_model:	False
i_frame:	6800,	i_episode:	397,	mean reward:	-575.78,	is_saved_model:	False
i_frame:	6900,	i_episode:	402,	mean reward:	-534.8,	is_saved_model:	False
i_frame:	7000,	i_episode:	409,	mean reward:	-571.64,	is_saved_model:	False
i_frame:	7100,	i_episode:	414,	mean reward:	-553.21,	is_saved_model:	False
i_frame:	7200,	i_episode:	423,	mean reward:	-542.02,	is_saved_model:	False
i_frame:	7300,	i_episode:	427,	mean reward:	-589.14,	is_saved_model:	False
i_frame:	7400,	i_episode:	436,	mean reward:	-541.12,	is_saved_model:	False
i_frame:	7500,	i_episode:	445,	mean reward:	-572.43,	is_saved_model:	False
i_frame:	7600,	i_episode:	452,	mean reward:	-549.58,	is_saved_model:	False
i_frame:	7700,	i_episode:	460,	mean reward:	-571.18,	is_saved_model:	False
i_frame:	7800,	i_episode:	479,	mean reward:	-519.05,	is_saved_model:	True
i_frame:	7900,	i_episode:	491,	mean reward:	-546.29,	is_saved_model:	False
i_frame:	8000,	i_episode:	492,	mean reward:	-536.35,	is_saved_model:	False
i_frame:	8100,	i_episode:	498,	mean reward:	-550.02,	is_saved_model:	False
i_frame:	8200,	i_episode:	504,	mean reward:	-542.77,	is_saved_model:	False
i_frame:	8300,	i_episode:	508,	mean reward:	-590.9,	is_saved_model:	False
i_frame:	8400,	i_episode:	512,	mean reward:	-621.1,	is_saved_model:	False
i_frame:	8500,	i_episode:	514,	mean reward:	-644.75,	is_saved_model:	False
i_frame:	8600,	i_episode:	518,	mean reward:	-598.1,	is_saved_model:	False
i_frame:	8700,	i_episode:	522,	mean reward:	-614.39,	is_saved_model:	False
i_frame:	8800,	i_episode:	527,	mean reward:	-599.63,	is_saved_model:	False
i_frame:	8900,	i_episode:	530,	mean reward:	-612.41,	is_saved_model:	False
i_frame:	9000,	i_episode:	535,	mean reward:	-604.51,	is_saved_model:	False
i_frame:	9100,	i_episode:	546,	mean reward:	-535.57,	is_saved_model:	False
i_frame:	9200,	i_episode:	548,	mean reward:	-593.45,	is_saved_model:	False
i_frame:	9300,	i_episode:	554,	mean reward:	-626.89,	is_saved_model:	False
i_frame:	9400,	i_episode:	555,	mean reward:	-621.72,	is_saved_model:	False
i_frame:	9500,	i_episode:	565,	mean reward:	-545.56,	is_saved_model:	False
i_frame:	9600,	i_episode:	575,	mean reward:	-555.58,	is_saved_model:	False
i_frame:	9700,	i_episode:	579,	mean reward:	-584.54,	is_saved_model:	False
i_frame:	9800,	i_episode:	581,	mean reward:	-589.87,	is_saved_model:	False
i_frame:	9900,	i_episode:	588,	mean reward:	-549.3,	is_saved_model:	False
i_frame:	10000,	i_episode:	592,	mean reward:	-523.7,	is_saved_model:	False
i_frame:	10100,	i_episode:	596,	mean reward:	-570.55,	is_saved_model:	False
i_frame:	10200,	i_episode:	601,	mean reward:	-635.53,	is_saved_model:	False
i_frame:	10300,	i_episode:	603,	mean reward:	-658.57,	is_saved_model:	False
i_frame:	10400,	i_episode:	612,	mean reward:	-549.88,	is_saved_model:	False
i_frame:	10500,	i_episode:	618,	mean reward:	-573.16,	is_saved_model:	False
i_frame:	10600,	i_episode:	621,	mean reward:	-634.09,	is_saved_model:	False
i_frame:	10700,	i_episode:	626,	mean reward:	-636.81,	is_saved_model:	False
i_frame:	10800,	i_episode:	632,	mean reward:	-611.48,	is_saved_model:	False
i_frame:	10900,	i_episode:	636,	mean reward:	-637.07,	is_saved_model:	False
i_frame:	11000,	i_episode:	641,	mean reward:	-551.83,	is_saved_model:	False
i_frame:	11100,	i_episode:	643,	mean reward:	-570.09,	is_saved_model:	False
i_frame:	11200,	i_episode:	647,	mean reward:	-571.82,	is_saved_model:	False
i_frame:	11300,	i_episode:	655,	mean reward:	-571.12,	is_saved_model:	False
i_frame:	11400,	i_episode:	659,	mean reward:	-580.46,	is_saved_model:	False
i_frame:	11500,	i_episode:	668,	mean reward:	-588.03,	is_saved_model:	False
i_frame:	11600,	i_episode:	670,	mean reward:	-579.67,	is_saved_model:	False
i_frame:	11700,	i_episode:	675,	mean reward:	-613.86,	is_saved_model:	False
i_frame:	11800,	i_episode:	677,	mean reward:	-661.97,	is_saved_model:	False
i_frame:	11900,	i_episode:	686,	mean reward:	-565.53,	is_saved_model:	False
i_frame:	12000,	i_episode:	692,	mean reward:	-553.87,	is_saved_model:	False
i_frame:	12100,	i_episode:	695,	mean reward:	-592.02,	is_saved_model:	False
i_frame:	12200,	i_episode:	696,	mean reward:	-607.15,	is_saved_model:	False
i_frame:	12300,	i_episode:	701,	mean reward:	-633.19,	is_saved_model:	False
i_frame:	12400,	i_episode:	706,	mean reward:	-617.69,	is_saved_model:	False
i_frame:	12500,	i_episode:	714,	mean reward:	-567.26,	is_saved_model:	False
i_frame:	12600,	i_episode:	719,	mean reward:	-588.92,	is_saved_model:	False
i_frame:	12700,	i_episode:	726,	mean reward:	-564.41,	is_saved_model:	False
i_frame:	12800,	i_episode:	729,	mean reward:	-566.31,	is_saved_model:	False
i_frame:	12900,	i_episode:	732,	mean reward:	-601.93,	is_saved_model:	False
i_frame:	13000,	i_episode:	741,	mean reward:	-577.34,	is_saved_model:	False
i_frame:	13100,	i_episode:	748,	mean reward:	-553.83,	is_saved_model:	False
i_frame:	13200,	i_episode:	752,	mean reward:	-575.59,	is_saved_model:	False
i_frame:	13300,	i_episode:	756,	mean reward:	-605.27,	is_saved_model:	False
i_frame:	13400,	i_episode:	762,	mean reward:	-615.97,	is_saved_model:	False
i_frame:	13500,	i_episode:	767,	mean reward:	-595.58,	is_saved_model:	False
i_frame:	13600,	i_episode:	769,	mean reward:	-618.82,	is_saved_model:	False
i_frame:	13700,	i_episode:	774,	mean reward:	-612.83,	is_saved_model:	False
i_frame:	13800,	i_episode:	778,	mean reward:	-621.08,	is_saved_model:	False
i_frame:	13900,	i_episode:	783,	mean reward:	-565.37,	is_saved_model:	False
i_frame:	14000,	i_episode:	785,	mean reward:	-588.16,	is_saved_model:	False
i_frame:	14100,	i_episode:	790,	mean reward:	-598.87,	is_saved_model:	False
i_frame:	14200,	i_episode:	794,	mean reward:	-580.88,	is_saved_model:	False
i_frame:	14300,	i_episode:	798,	mean reward:	-580.51,	is_saved_model:	False
i_frame:	14400,	i_episode:	802,	mean reward:	-614.4,	is_saved_model:	False
i_frame:	14500,	i_episode:	813,	mean reward:	-539.61,	is_saved_model:	False
i_frame:	14600,	i_episode:	815,	mean reward:	-580.71,	is_saved_model:	False
